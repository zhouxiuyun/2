基于残差密集神经网络的压缩感知磁共振图像重建 

SA18023025 王志伦 电子科学与技术系 

 

摘要：磁共振成像可以为临床诊断提供空间和时间信息。然而，较慢的成像
速度仍是磁共振成像的挑战之一。大多数现有方法在压缩感知或低秩理论的指导
下从不完全 k 空间数据重建动态磁共振图像，迭代重建时间较长。最近，深度学
习在加速磁共振成像方面显示出巨大潜力。受到这一启发，本文提出了残差密集
网络用于磁共振成像。具体而言，密集网络充分利用了来自所有卷积层的分层特
征，残差则将局部特征和全局特征进行了融合。 

关键词:磁共振成像，深度学习，压缩感知，密集，  

 

1.引言 

磁共振成像是一种非侵入性成像技术，可以为底层解剖提供空间和时间信息。

然而，生理和硬件限制使得磁共振成像速度较慢，可能导致患者不适或产生运动
伪影。因此，加速磁共振成像是非常必要的。目前主要有三个加速成像的研究方
向，即开发基于物理的快速成像序列[1]，基于硬件的并行成像技术[2]和基于信
号处理的不完全 k 空间数据的磁共振图像重建方法。本文关注的是欠采样磁共振
图像重建，其需要先验信息来解决由违反奈奎斯特采样定理引起的混叠伪影。 
对于压缩感知磁共振(CS-MRI)[3,4], k-t FOCUSS[5]利用 x-f 支持的稀疏性

来重建来自欠采样 k-t 空间的 x-f 图像,包括 k-t BLAST 和 k-t SENSE[6]。k-t  
ISD [7]基于部分已知的 CS 理论，在 x-f 空间中利用了关于图像的附加信息.DLTG 
[8]可以通过对时间梯度（TG）稀疏性的辅助约束来学习数据中的冗余信息。此
外，可以使用低秩和不相干条件来补全矩阵丢失或损坏的信息。低秩的一个典型
例子是 L+S[10]，其中核范数用于增强 L 中的低秩，而𝑙1范数用于增强 S 中的稀
疏性。而 kt  SLR[11]通过对数据建模以在 KLT 变换域中具有紧凑表示来利用动
态成像数据集中的相关性。这些方法在加速成像方面取得了很大进展，效果得到
了改进。然而，这些方法仅从有限的样本中提取先验信息，且迭代重建耗时较长。 

另一方面，深度学习在加速磁共振成像方面显示出巨大的潜力。现有的方法
可以大致分为两种类型，基于模型的展开方法和端到端学习方法。基于模型的展
开方法是将传统优化算法的迭代过程变换为网络学习。他们通过网络训练自适应
地学习正则项的所有参数并在模型中进行变换。例如，在 VN-Net[12]中，将压缩
感知重建公式化为变分模型嵌入到梯度下降方案中。ADMM-Net[13]则从用于优化
基于压缩感知的磁共振成像的交替方向乘法器（ADMM）算法中的迭代过程导出数
据流图。端到端学习方法又可以分为四类。一是直接在 k 空间进行重建，然后通
过傅里叶逆变换(IFT)得到重建图像。此类方法直接恢复缺失的 k 空间数据，难
度较大，如[14]使用残差 U-net 在 k 空间重建图像。二是先对欠采样 k 空间数据
做 IFT，然后在图像域进行重建。这是目前常用的一类方法。在深度级联神经网
络[15,16]中，引入了数据一致层，尽可能保留欠采样数据中的信息。复卷积网
络[17]引入了复数卷积、池化、正则化等运算重建出复值图像。密集卷积神经网
络[18]引入了密集连接层来充分利用提取到的特征。三是跨域重建，即先在 k 空
间重建，再通过 IFT 在图像域重建。这类方法可以充分利用不同域的数据信息。

W-net[19]分别使用两个完全相同的 U-net 进行 k 空间和图像域的重建。
DIMENSION[20]则使用不同长度的卷积级联网络分别在两个域进行重建。四是直
接从 k 空间重建图像，不经过 IFT 过程。最著名的方法是 AUTOMAP[21]，首次将
全连接层作为神经网络的输入层，利用流形学习获得了很好的重建结果。但全连
接层参数数目远多于卷积层，所以难以用于大尺度图像重建。 

在本文中，我们提出级联的残差密集网络用于磁共振图像重建，简称为 CRDN。

我们的贡献可归纳如下： 
1）在这项工作中，我们将用于图像超分辨率重建的残差密集模块(RDB)[22]引入
压缩感知磁共振重建，同时利用局部特征和全局特征。 
2）我们利用具有边缘增强特性的全变差（TV）损失函数来训练网络。 

2.方法 

2.1 压缩感知磁共振成像 

根据压缩感知（CS）[3,4]理论，可以从随机欠采样的 k 空间数据重建出在一些
变换域中具有稀疏表示的磁共振图像。让S ∈ ∁𝑁𝑥𝑁𝑦𝑁𝑡表示复值磁共振图像,则问
题可以通过以下公式来描述： 

𝐾𝑢 =   𝐹𝑢𝑆 + 𝑒                                                      (1) 
其中𝐾𝑢 ∈ ∁𝑁𝑥𝑁𝑦𝑁𝑡是 k 空间中的欠采样测量值，未采样点用零填充。𝐹𝑢是欠采样
傅立叶编码矩阵，e ∈ ∁𝑁𝑥𝑁𝑦𝑁𝑡是采集噪声。为了重建𝑆，我们通过添加一些先验
知识来约束这个逆问题并转化为解决如下优化问题： 

1
2

min

𝑆

||𝐹𝑢𝑆 − 𝐾𝑢||2

2 + 𝑅(𝑆)                                        (2) 

上式中第一项是数据保真度，它确保重建的 k 空间数据与实际测量的 k 空间数据
一致。第二项通常被称为先验正则项。在压缩感知的方法中，𝑅(𝑆)在一些变换域
（如有限差分，小波变换和离散余弦变换）中通常是𝑅(𝑆)的稀疏先验。在基于卷
积神经网络(CNN)的方法中，𝑅(𝑆)是𝑆的 CNN 先验，它迫使𝑆匹配网络的输出： 

1
2

min

𝑆

||𝐹𝑢𝑆 − 𝐾𝑢||

2

2

2
+ 𝜆||𝑆 − 𝑓𝐶𝑁𝑁(𝑆𝑢|𝜃)||
2

                            (3) 

其中𝑆𝑢是欠采样图像，𝑓𝐶𝑁𝑁(𝑆𝑢|𝜃)是参数𝜃下网络的输出。网络的训练过程是找到
最佳参数𝜃∗。网络训练完成后，网络的输出𝑓𝐶𝑁𝑁(𝑆𝑢|𝜃∗)就是我们想要的重建图像。 
2.2 提出的方法 

2.2.1 级联残余密集网络 

在这项工作中，我们提出用于大脑磁共振图像重建的级联残差密集网络
（CRDN）（如图 1 所示），采用了跨域学习思想。网络框架包括 k 空间和图像域级
联残差密集网络（CRDN），这两部分通过傅立叶反变换连接。 

 

图 1 级联残差密集网络 

图 1 中上方为整个网络的结构，其中 block 的组成如左下角所示，由四个残
差密集块(RDB)[22]、一个全局特征融合层、一个卷积层、一个全局残差连接层
组成。每个 RDB 结构如右下角所示，由一个输入卷积层、五个密集连接层、一个
局部特征融合层和一个局部残差连接层组成。 

上述神经网络的计算过程如下：首先，将欠采样的大脑磁共振图像输入网络
进行浅层特征提取。其次，浅层特征通过密集连接层后进行局部特征融合。密集
连接指的是直接将每个卷积层与后续卷积层沿着通道方向进行拼接，可以增强局
部特征的传输。所有局部特征连接在一起并通过 1*1 卷积层以实现局部特征融
合。RDB 中还引入了局部残差连接，以防止梯度消失。然后，来自四个 RDB 的这
些残差密集特征通过全局特征融合(沿通道方向拼接+1*1 卷积）合并。通过局部
特征融合和全局特征融合可以充分利用不同层次的特征。最后，全局残差连接将
浅层特征与全局特征相结合，生成重建图像。 

2.2.2 边缘增强的损失函数 

与经典压缩感(CS)或基于低秩的方法相比，基于 CNN 的方法[15,21,22]可以在更
短的时间内实现改进的重建结果[5,10,11]。然而，在高加速因子下，重建图像
仍然存在一定程度的平滑。部分原因可能是这些工作中使用平均平方误差(MSE)
作为损失函数。MSE 损失函数仅表示重建图像与真实情况之间的均方信息，而不
能感知图像结构信息。本文引入全变差（TV）约束作为损失函数的一项。TV 包括
各向异性 TV，各向同性 TV 和高等 HDTV[23]。设𝑆为 CRDN 的输出，则各向异性 TV
可定义为： 

𝑇𝑉𝑎𝑛𝑖𝑠𝑜(𝑆̂) =   ∫ |

𝛺

𝜕𝑆̂(𝑟)

𝜕𝑥

| + |

各向同性 TV 可定义为： 

𝜕𝑆̂(𝑟)

𝜕𝑦

| 𝑑𝑟

                          (4) 

𝑇𝑉𝑖𝑠𝑜(𝑆̂) =   ∫ √(

𝛺

𝜕𝑆̂(𝑟)

𝜕𝑥

2
)

+ (

𝜕𝑆̂(𝑟)

𝜕𝑦

2
)

𝑑𝑟

                        (5) 

HDTV 的推导和证明可以在[23]中看到。在这里，我们直接给出 2DTV 的计算公式： 

2𝐷𝑇𝑉(𝑆) =   ∫ √(3|𝑆𝑥𝑥|2 + 3|𝑆𝑦𝑦|

2

2

+ 4|𝑆𝑥𝑦|

+ 2𝑅(𝑆𝑥𝑥𝑆𝑦𝑦))/8

𝑑𝑟      (6) 

𝛺

其中𝑆𝑥𝑥，𝑆𝑦𝑦，𝑆𝑥𝑦均为对应方向的二阶微分，𝑅表示取实部。 

3 实验与分析 

3.1 数据采集和预处理 

本实验所用的大脑磁共振图像来自 MGH-USC HCP[24]公共数据库。这些数据是通
过西门子 Skyra 3T MRI 平台（Siemens Medical Solutions，Erlangen，Germany）
的 T1 加权三维 MRI 采集协议 MPRAGE 获得的。成像参数如下：重复时间 TR  = 
2,530ms，回波时间 TE = 1.15ms，反转时间 TI = 1,100ms，翻转角 FA = 7.0°，
带宽 BW  =  651Hz。HCP 协议掩盖了面部和耳朵区域以保护受试者隐私。来自 35
个受试者的轴向，矢状和冠状 T1 加权切片用于生成 32,000 个图像数据集。对于
每个图像，中心 256×256 像素被裁剪并二次采样到 128×128。为了促进训练中
的平移不变性，每个图像被对称地平铺以创建包含原始的四个反射的更大的
256×256 图像，并且裁剪为随机的 128×128 部分。然后以 90°的增量旋转每个
图像以增加数据集。最后减去每个图像的平均强度，并将整个数据集标准化为由
数据集的最大强度定义的恒定值。在测试实验中使用的数据取自用于同一数据集
中不同的受试者。 

3.2 网络训练 

对于网络训练，将输入的欠采样 k 空间数据分成两个通道，分别存储数据的
实部和虚部。因此，网络的输入是欠采样的 k 空间𝑅2𝑁𝑥𝑁𝑦𝑁𝑡，输出是重建图像
𝑅2𝑁𝑥𝑁𝑦𝑁𝑡。频域和图像域分别使用一个 CRDN 模块，每个块包含四个 RDB 块，每
个 RDB 块由四个密集连接层。Xavier 初始化[25]用于初始化网络权重。选择整
流器线性单元（ReLU）[26]作为非线性激活函数。指数衰减学习率用于所有基于
CNN 的实验，批量大小为 16，初始学习率设定为 0.0001，衰减为 0.95。所有模
型都由 Adam 优化器[27]训练，参数𝛽1=0.9,𝛽2=0.999,ε=1e-8。模型在 Ubuntu 
16.04  LTS（64 位）操作系统上实现，配备有英特尔至强 E5-2640 中央处理器
（CPU）和特斯拉 TITAN Xp 图形处理单元（GPU，12GB 内存）在开放框架 Tensorflow 
[28]中，支持 CUDA 和 CUDNN。 

3.3 性能评估 

对于定量评估，均方误差（MSE），峰值信噪比（PSNR）和结构相似性指数（SSIM）

[29]测量如下： 

2
MSE =   ||𝑅𝑒𝑓 − 𝑅𝑒𝑐||

                                      (7) 

PSNR = 20lg

max(𝑅𝑒𝑓) √𝑁
||𝑅𝑒𝑓 − 𝑅𝑒𝑐||

2

                                  (8) 

SSIM = 𝑙(𝑅𝑒𝑓, 𝑅𝑒𝑐) ∗ 𝑐(𝑅𝑒𝑓, 𝑅𝑒𝑐) ∗ 𝑠(𝑅𝑒𝑓, 𝑅𝑒𝑐)            (9) 
其中𝑅𝑒𝑐是重建图像，𝑅𝑒𝑓表示参考图像，𝑁是图像像素的总数。 SSIM 指数是亮
度项，对比项和结构项的乘法组合。 

3.4 结果与分析 

利用 CRDN 模型对 25%欠采样的 k 空间数据重建结果如图 2 所示： 

 

图 2 CRDN 重建结果 第一行是重建图像，第二行是原图 

可以看出，重建图像没有明显的平滑，说明边缘增强的损失函数是有效的。 
本文提出的方法与 W-net[18], DIMENSION[19]的定量比较如表 1 所示： 

 

MSE 
PSNR 
SSIM 

表 1.三种方法重建结果的定量比较 

W-net 

0.00147 

33.12 
0.924 

DIMENSION 

0.00152 

34.29 
0.937 

CRDN 

0.00135 

34.58 
0.951 

从表 1 可以看出，CRDN 的重建结果优于其他两种方法，主要是因为使用了
密集连接层，充分利用了局部特征。但密集连接层的使用也使得计算复杂度和计
算时间大大增加，重建单张图像的时间在 100ms 左右。 

4.结论和展望 

本文提出用于欠采样磁共振成像重建的级联残余密集网络和具有边缘增强
效果的损失函数。相比与经典的 k-t FOCUSS，k-t SLR，L+S 和基于深度学习的
最新方法，重建效果可以更好，重建时间较长，但仍可以接受。 

参考文献 

[1] W. Kaiser and E. Zeitler, “MR imaging of the breast:fast imaging sequences with 
and without Gd-DTPA.preliminary observations.” Radiology, vol. 170, no. 3, pp.681–
686, 1989. 
[2] D. K. Sodickson and W. J. Manning, “Simultaneous acquisition of spatial harmonics 
(SMASH): fast imaging with radiofrequency coil arrays,” Magnetic Resonance in 
Medicine, vol. 38, no. 4, pp. 591–603, 1997. 
[3] D. L. Donoho, “Compressed sensing,” IEEE Transactions on Information Theory, 
vol. 52, no. 4, pp. 1289–1306,2006 
[4] M. Lustig, D. Donoho, and J. M. Pauly, “Sparse MRI:The application of compressed 
sensing for rapid MR imaging,” Magnetic Resonance in Medicine, vol. 58, 
no. 6, pp. 1182–1195, 2007. 
[5]  H.  Jung,  J.  C. Ye,  and  E. Y.  Kim,  “Improved  k–t  BLAST  and  k–t  SENSE  using 
FOCUSS,” Physics in Medicine & Biology, vol. 52, no. 11, p. 3201, 2007. 
[6] J. Tsao, P. Boesiger, and K. P. Pruessmann, “k-t BLAST and k-t SENSE: dynamic 
MRI with high frame rate exploiting spatiotemporal correlations,” Magnetic Resonance 
in Medicine, vol. 50, no. 5, pp. 1031–1042, 2003. 
[7] D. Liang, E. V. DiBella, R.-R. Chen, and L. Ying, “kt ISD: dynamic cardiac MR 

imaging  using  compressed  sensing  with  iterative  support  detection,”  Magnetic 
Resonance in Medicine, vol. 68, no. 1, pp. 41–53, 2012. 
[8] J. Caballero, A. N. Price, D. Rueckert, and J. V. Hajnal, “Dictionary learning and 
time sparsity for dynamic MR data reconstruction,” IEEE Transactions on Medical 
Imaging, vol. 33, no. 4, pp. 979–994, 2014. 
[9] Y. Wang and L. Ying, “Compressed sensing dynamic cardiac cine MRI using learned 
spatiotemporal dictionary.” IEEE Trans. Biomed. Engineering, vol. 61, no. 4, pp. 
1109–1120, 2014. 
[10]  R.  Otazo,  E.  Candes,  and  D.  K.  Sodickson,  “Low-rank  plus  sparse  matrix 
decomposition  for  accelerated  dynamic  MRI  with  separation  of  background  and 
dynamic components,” Magnetic Resonance in Medicine, vol. 73, 
no. 3, pp. 1125–1136, 2015. 
[11]  S.  G.  Lingala,  Y.  Hu,  E.  DiBella,  and  M.  Jacob,  “Accelerated  dynamic  MRI 
exploiting sparsity and lowrank structure: k-t SLR,” IEEE Transactions on Medical 
Imaging, vol. 30, no. 5, pp. 1042–1054, 2011. 
[12] J. Sun, H. Li, Z. Xu et al., “Deep ADMM-Net for 
compressive  sensing  MRI,”  in  Advances  in  Neural  Information  Processing  Systems, 
2016, pp. 10–18. 
[13] K. Hammernik, T. Klatzer, E. Kobler, M. P. Recht, D. K. Sodickson, T. Pock, and 
F. Knoll, “Learning a variational network for reconstruction of accelerated MRI data,” 
Magnetic Resonance in Medicine, vol. 79, no. 6, pp.3055–3071, 2018. 
[14]  Han,  Yoseob,  and  Jong  Chul  Ye.  "k-space  deep  learning  for  accelerated 
MRI." arXiv preprint arXiv:1805.03779 (2018). 
[15] Schlemper, Jo, et al. "A deep cascade of convolutional neural networks for dynamic 
MR image reconstruction." IEEE transactions on Medical Imaging 37.2 (2017): 491-
503. 
[16  Dar,  Salman  Ul  Hassan,  and  Tolga  Çukur.  "A  transfer-learning  approach  for 
preprint 
accelerated  MRI 
arXiv:1710.02615 (2017).] 
[17] Dedmari, Muneer Ahmad, et al. "Complex Fully Convolutional Neural Networks 
for  MR  Image  Reconstruction." International  Workshop  on  Machine  Learning  for 
Medical Image Reconstruction. Springer, Cham, 2018. 
[18]  Ding,  Pak  Lun  Kevin,  et  al.  "Deep  residual  dense  U-Net  for  resolution 
enhancement  in  accelerated  MRI  acquisition." Medical  Imaging  2019:  Image 
Processing. Vol. 10949. International Society for Optics and Photonics, 2019. 
[19] Souza, Roberto, and Richard Frayne. "A Hybrid Frequency-domain/Image-domain 
Deep  Network  for  Magnetic  Resonance  Image  Reconstruction." arXiv  preprint 
arXiv:1810.12473(2018). 
[20] Wang, Shanshan, et al. "Dimension: Dynamic mr imaging with both k-space and 
spatial prior knowledge obtained via multi-supervised network training." arXiv preprint 
arXiv:1810.00302(2018). 
[21]  Zhu,  Bo,  et  al.  "Image  reconstruction  by  domain-transform  manifold 
learning." Nature 555.7697 (2018): 487. 
[22]  Zhang,  Yulun,  et  al.  "Residual  dense  network 

networks." arXiv 

neural 

image 

super-

using 

deep 

for 

resolution." Proceedings  of  the  IEEE  Conference  on  Computer  Vision  and  Pattern 
Recognition. 2018. 
[23] Y. Hu and M. Jacob, “Higher degree total variation (hdtv) regularization for image 
recovery,”  IEEE  Transactions  on  Image  Processing,  vol.  21,  no.  5,  pp.  2559–2571, 
2012. 
[24] Fan, Q. et al. MGH–USC Human Connectome Project datasets with ultra-high b-
value diﬀusion MRI. Neuroimage 124, 1108–1114 (2016). 
[25]  Glorot,  X.,  and  Y.  Bengio.  "Understanding  the  difficulty  of  training  deep 
feedforward neural networks. 2010." Received February 12 (2018). 
[26] X. Glorot, A. Bordes, and Y. Bengio, “Deep sparse rectifier neural networks,” in 
Proceedings of The Fourteenth International Conference on Artificial Intelligence and 
Statistics, 2011, pp. 315–323. 
[27]D.  P.  Kingma  and  J.  Ba,  “Adam: A  method  for  stochastic  optimization,”  arXiv 
preprint arXiv:1412.6980, 2014. 
[28] M. Abadi, P. Barham, J. Chen, Z. Chen, A. Davis, J. Dean, M. Devin, S. Ghemawat, 
G. Irving, M. Isard et al., “Tensorflow: a system for large-scale machine learning.” in 
OSDI, vol. 16, 2016, pp. 265–283. 
[29]  Z.  Wang,  A.  C.  Bovik,  H.  R.  Sheikh,  and  E.  P.  Simoncelli,  “Image  quality 
assessment: from error visibility to structural similarity,” IEEE Transactions on Image 
Processing, vol. 13, no. 4, pp. 600–612, 2004 

